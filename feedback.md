# Assignment Feedback: Week 4: Dimensionality Reduction

**Student:** ppawar03-byte
**Total Score:** 26/40 (65.0%)

**Grade Category:** D (Poor)

---

## Problem Breakdown

### Exercise 1 (8/16 = 50.0%)

**Part pipeline-part1** (pipeline-part1.code): 0/0 points

_Feedback:_ You correctly applied PCA to 2D and visualized a scatter colored by labels—meets the basic goal. To improve: visualize reconstructions (inverse_transform) of digits, report explained_variance_ratio_, and try multiple n_components to show approximation quality trade-offs.

**Part pipeline-part2** (pipeline-part2.code): 2/4 points

_Feedback:_ You correctly fit PCA and produced a scree plot, showing understanding of variance explained. However, the task asked to reduce to 2 components and visualize a 2D scatter colored by class. No 2D embedding or class-colored scatter was provided. Add PCA(n_components=2) and scatter.

**Part pipeline-part3** (pipeline-part3.code): 1/4 points

_Feedback:_ You computed cumulative explained variance and a 95% threshold, but the task was to calculate and visualize a scree plot for the first 40 components with y-axis as percent of variance explained. No plot was produced. Plot pca_full.explained_variance_ratio_[:40] with proper labels

**Part pipeline-part4** (pipeline-part4.code): 4/4 points

_Feedback:_ Good job. You correctly computed n_components_95_variance earlier and used it here to fit PCA and reconstruct a digit. This leverages your prior step appropriately. While this cell doesn’t recompute or print the number, your earlier code did, so full credit.

**Part pipeline-part5** (pipeline-part5.code): 1/4 points

_Feedback:_ You didn’t perform the requested visualization. The task was to reconstruct and plot a digit using the number of PCA components from Step 4 (95% variance) and plot_mnist_digit. Your code trains KNN with PCA (80%) and no plot. Use pca_95, inverse_transform, and plot the same digit

---

### Exercise 2 (9/10 = 90.0%)

**Part ex1-part1** (ex1-part1.code): 4/4 points

_Feedback:_ Correct use of t-SNE to 2D and clear visualization colored by labels. Random state set and plot parameters sensible. This meets the task requirements. Optionally, you could tune perplexity or subsample for speed, but not required. Good job.

**Part ex1-part2** (ex1-part2.code): 2/3 points

_Feedback:_ Good attempt: you trained KNN on t-SNE embeddings and reported performance with interpretation. However, you re-fit t-SNE on the test set, so train/test are in different embedding spaces—KNN predictions are invalid. Embed once, then split (or embed all, then split).

**Part ex1-part3** (ex1-part3.code): 3/3 points

_Feedback:_ Good job. You correctly trained KNN on the UMAP-transformed training data, transformed the test set with the same model, and computed accuracy. This follows from your prior UMAP work and meets the task requirements.

---

### Exercise 4 (9/14 = 64.3%)

**Part ex2-part1** (ex2-part1.code): 0/0 points

_Feedback:_ Good PCA pipeline: 2D/3D transforms, KNN eval, and visualizations. However, you didn’t implement UMAP or vary its parameters, which was central to the task. Add UMAP (try n_components 2–3, sweep n_neighbors and min_dist) and compare KNN accuracies/plots.

**Part ex2-part2** (ex2-part2.code): 3/7 points

_Feedback:_ You implemented UMAP, not PCA as required and not consistent with your prior PCA-based work. While you did proper DR+KNN with 2D/3D visuals, it doesn’t satisfy the PCA task. Replace UMAP with PCA and transform train/test accordingly. Also avoid fitting on full X before split.

**Part ex2-part3** (ex2-part3.answer): 6/7 points

_Feedback:_ Good comparative insight: UMAP clusters well, parameter sensitivity noted; PCA often stronger for classification. However, you didn’t report concrete results from your run (accuracies) or parameter values tried, and the “linearly separable” claim lacks evidence. Add metrics to ju

---

## Additional Information

This feedback was automatically generated by the autograder using LLM-based evaluation.

**Generated:** 2025-10-27 18:51:13 UTC

If you have questions about your grade, please reach out to the instructor.

---

*Powered by [Grade-Lite](https://github.com/your-repo/grade-lite) Autograder*